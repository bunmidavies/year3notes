# chip multiprocessors

### course division
- Part A - Introduction 
- Part B - Multiprocessor Programming and Hardware Support
- Part C - Other Approaches
### reading
- [[Computer-Architecture-A-Quantitative-Approach.pdf|Computer Architecture - A Quantitative Approach]]
### assessment
- Lab 1: Delivering speedup for vector addition - 23 feb
- Lab 2: Synchronisation: the dining philosophers problem - 15 mar
- Lab 3: Relaxation (to solve Poisson's equation) - 26 apr

> [!note] week 1
> - [intro 1 slides](https://olivierpierre.github.io/comp35112/lectures/01a-introduction-1/#1)
> - intro live lecture: logistics, why multiprocessors? transistor count timeline - ==architectural approaches to increasing single processor clock speed have been exhausted==, moores law (mostly due to transistor size reduction)
>   <br>
>   
> - Lecture 1: Introduction
> 	- [[dennard scaling]] - single core performance hits wall, resort to multicore, resulting in parallelism to be exploited
> 	- [[instruction-level parallelism (ILP)]] - low amount of parallelism to be extracted
> 	- [[thread-level parallelism (TLP)]] - higher amount of parallelism to be extracted
> 	- [[data-level parallelism (DLP)]]
> 	- [[chip multiprocessor considerations]] - hardware/software divide
> 	- [reading: 'The Free Lunch Is Over', Herb Sutter, 2005](http://www.gotw.ca/publications/concurrency-ddj.htm)
> 
>   <br>
> - Lecture 2: The World of Parallelism
> 	- trends of core count so far: seemingly doubling every year - at this rate, by 2030 even mid-range smartphones may have 100+ general purpose cores
> 	- [[flynn's taxonomy]] - a way to classify parallel computer architectures
> 	- [[on chip interconnects]] - between cores and between cores and memory:
> 		- grid interconnect
> 		- torus interconnect
> 		- bus interconnect
> 	- [[shared memory vs distributed memory]] - in general, implementations must balance between ease of programming and hardware efficiency