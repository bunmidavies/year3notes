<title>Clocking</title>

<html>
<head>

<style>
table, th, td {
  border: 1px solid black;
}
</style>

<style>
* {
  box-sizing: border-box;
}

/* Create two equal columns that float next to each other */
.column {
  float: left;
  width: 50%;
  padding: 10px;
}

/* Clear floats after the columns */
.row:after {
  content: "";
  display: table;
  clear: both;
}
</style>

<style>
.inset {
  float: none;
  width: 80%;
  border: 2px outset red;
  background-color: lightgray;
  text-align: center;
}
div.left {text-align:left;}
</style>

<style>
h1 {text-align: center;}
</style>

</head>

<body>

<p align="center">
<span style="color:green;">Pages marked <span style="color:red;font-size:24px">&star;</span>
should be revision from COMP22111.</span>
</p>

<hr>

<h3 id="index";>Timing: links</h3>

<h4>In this session</h4>
<ul>
<li><a href="05a_clocking.html">Clocking.</a></li>
<li><a href="05b_timing closure">Timing closure.</a></li>
<li><a href="05c_time_stealing">Time stealing.</a></li>
<li><a href="05d_clock_domains.html">Clock domains.</a></li>
<li><a href="05e_example.html">Clock generation.</a></li>
<li><a href="05f_more.html">** TBC **.</a></li>
</ul>

<h4>Other</h4>
<ul>
<li><a href="03_testing.html">Previous session's notes</a>: verification.</li>
<li><a href="05_timing.html">Next session's notes</a>: timing.</li>
<li><a href="index.html">Up to Index.</a></li>
</ul>

<hr>

<h2 id="conclusions";>Conclusions</h2>
<ul>
<li> There are many factors to consider when setting out to build a system
<li> You probably won't find &lsquo;the optimum&rsquo; solution &hellip;
  <ul>
  <li> is it worth trying?
  <li> will the &lsquo;goalposts&rsquo; move?
  <li> there are probably things you don't know
  </ul>
<li> &hellip; but you should aim to get close
<li> Your design constraints may differ from project to project
  <ul>
  <li> speed is tempting but fast enough is fast enough
  <li> power (energy) increasingly important &ndash; more later
  <li> area smaller is probably better
  <li> simplicity improves time to market (or
  &lsquo;reliability&rsquo;)
  </ul>
</ul>

<p><a href="05_timing.html">Next session's notes</a>: timing.</p>

<hr>



<h1>Clocking <span style="color:red;font-size:24px">&star;</span></h1>

<p>
The synchronous model is an enormous simplification in designing
working Finite State Machines.
</p>

<p>
For this to work there are certain assumptions.
</p>


<div class="row">
  <div class="column">
  <center>
  <img src="figures/one_flip_flop.png" alt="D-type flip-flop" width=80%>
  </center>
  </div>

  <div class="column">

  <ul>
  <li>data set up time (t<sub>su</sub>)</li>

    <ul>
    <li>data stability before the clock</li>
    </ul>

  <li>data hold time (t<sub>hold</sub>)</li>

    <ul>
    <li> data stability after the clock</li>
    </ul>

  <li>propagation delay (t<sub>pd</sub>)</li>
    <ul>
    <li>output lag after the clock</li>
    </ul>

  </ul><br clear="right">
  </div>
</div>

<p>In the synchronous model it is assumed that one flip-flop can feed
  another.</p>

<img src="figures/two_flip_flops.png" alt="Two D-type flip-flops" align="right" width=40%>

<p>Which means this <span style="color:green">(points to figure on
    right)</span> is possible:</p>

<p><i>assuming the clock reaches both (all) devices
&lsquo;simultaneously&rsquo;.</i></p>

<p>i.e. minimal <b>clock skew</b>.</p>
<br clear="right"><p>&nbsp;</p>

<center>
<div class="inset">

<h3>Data hold times</h3>

<p>
It is important to meet all the flip-flop timing constraints if a
circuit is to work under all circumstances.  However observe:
</p>

<ul style="text-align:left">
<li>The <b>set up</b> time depends on racing through any intervening logic
  from one active clock edge to the <b>next</b>.</li>

<li>The <b>hold</b> time depends on <i>not</i> passing through any
  intervening logic so quickly
  after an active clock edge that it affects subsequent flip-flops at
  the <b>same</b> active clock edge.</li>
</ul>

<p>
If a set up violation is
introduced <span style="color:green">(oops!)</span> it can be avoided
by increasing the clock period<sup>&dagger;</sup>.  A hold-time
violation is fatal however, since nothing can be done externally.
</p>

<p>
Don't worry <i>too</i> much; most CAD tools will look for possible
hold violations and add some buffers (&lsquo;do nothing&rsquo; logic)
to slow down signals which would otherwise be too fast.  You might see
this in synthesis reports.
</p>

<blockquote style="font-size:12px;">
<sup>&dagger;</sup>Assuming the application can tolerate the slow-down.
</blockquote>


</div>
</center>

<hr>


<h2>Clock distribution <span style="color:red;font-size:24px">&star;</span></h2>

<p>
In practice clock arrival times have to be &lsquo;close enough&rsquo;.
</p>

<ul>
<li> The <i>difference</i> in arrival times is referred to as
  &lsquo;<b>clock skew</b>&rsquo;.

<li> In almost all practical cases, it must be minimised.
</ul>

<h3>Observations on clock distribution</h3>

<ul>
<li> Clocks have high fan-out
  <ul>
  <li> a clock may fan out to thousands of flip-flops
  </ul>

<li> Clock edges should be &lsquo;fast&rsquo;
  <ul>
  <li> Slow edge speeds increase the uncertainty in exactly when the
       transition &lsquo;happens&rsquo;
  </ul>

<li> Clock signals are repetitive
  <ul>
  <li> The latency of a clock reaching a flip-flop doesn't matter
  <li> They always arrive at regular intervals
  </ul>
</ul>

<img src="figures/clock_tree.png" alt="Clock tree" align="right" width=20%>

<p>
These properties mean that clock signals require buffers &hellip; but
that's okay providing the skew is still kept small.
</p>

<p>
The clock tree needs to be well balanced, taking into consideration:
</p>

<ul>
<li> Fan-out at each point

<li> Buffer strength

<li> Wire lengths
</ul>

<p>
This is a big task for &lsquo;Place and Route&rsquo;:
fortunately, tools will help with this.
</p>

<center>
<img src="figures/H_tree.png" alt="Clock H-tree" width=40%>
</center>

<p>
The classic &lsquo;<b>H-tree</b>&rsquo; structure is one method of
trying to distribute a clock across a chip with minimal skew.  Note,
all paths are (notionally) the same length.
</p>

<h3>Reset skew</h3>

<p>
Reset activation is not normally a timing problem because reset will
be present for some time.  The <i>removal</i> of reset can be a problem
though.  Imagine reset being removed in one part of a state machine but
not quite making it to another.  This could cause the machine to enter
an illegal state.  It is sometimes necessary to synchronise an
otherwise asynchronous reset to prevent this.
</p>


<center>
<div class="inset">

<h3>FPGA clock distribution</h3>

<p>
Modern FPGAs have a dedicated set of clock distribution networks built
onto the chip which deliver clock signals to all flip-flops with minimal
skew.  There are typically a small number (e.g. four) of these networks so
that a number of different clocks may be used.  These networks can only be
used for clocking flip-flops.
</p>

</div>
</center>

<hr>

<h2>Timing Closure <span style="color:red;font-size:24px">&star;</span></h2>

<h3>Simulation</h3>

<ul>
<li> Okay for a rough-cut

<li> May be difficult to simulate <b>critical path</b>
  <ul>
  <li> the &lsquo;longest&rsquo; (slowest!) path between registers
  </ul>
</ul>


<img src="figures/STA.png" alt="Static timing analysis" width= 40% align="right">

<h2>Static timing analysis (STA)</h2>

<ul>
<li> Take blocks of logic between synchronously clocked elements

<li> Time all possible switching paths in block

<li> Find the longest
</ul>
<br clear="right">

<h3>Advantage</h3>
<ul><ul>
<li> Quick to perform
</ul></ul>

<h3>Disadvantages</h3>
<ul><ul>
<li> Should give a <i>conservative</i> upper bound
<li> Can be too pessimistic
</ul></ul>

<p>
Timing closure is, basically, making the logic fit within the desired
clock period.
</p>

<h4>How fast does it go?</h4>

<p>
This can be difficult to determine, exactly.  It is set by the critical
path.  From a HDL source this requires at least technology mapping into
gates.  Accuracy requires knowledge of gate strengths, wire load and
layout detail.  However it is cost effective to estimate timing early
to check that the implementation strategy is feasible.  Even pre-layout
the tools usually give an estimate of the wire loads to yield a more
realistic result.
</p>

<h4>Simulation</h4>

<p>
Simulation can indicate whether a particular sequence will fail at a
particular clock speed.  This is a reasonable guide but is not reliable
unless either the critical path is known (and exercised) or the
simulation is exhaustive.
</p>

<p>
Example: a ripple carry adder.  Simulation with random inputs is
unlikely to find the slowest case, when a carry propagates across the
whole width.
</p>

<h4>Static Timing Analysis (STA)</h4>

<p>
In this case &lsquo;static&rsquo; means independent of input state.
The delays through each combinatorial path can be summed and compared
with the design objective.  This reveals the critical path or the
&lsquo;<b>slack</b>&rsquo; in all logic paths.  In the latter case
&lsquo;<b>negative slack</b>&rsquo; will reveal where the logic is too
slow.
</p>

<center><font style="color:blue;font-size:30px">** Expand on 'slack';
    maybe add an inset? **</font></center>

<p>
The great advantage of static analysis is its low computational
complexity.  The disadvantage is that the &lsquo;critical path&rsquo; may be a
false path, i.e. one whose switching sequence cannot occur in reality.
</p>

<p>
In general STA will identify anything which is significantly bad at
low cost.
</p>

<h4>Does it go fast enough?</h4>

<p>
No, of course it doesn't; where would the fun be in that? 
</p>

<p>
Seriously, what is &lsquo;fast enough&rsquo;? In many applications
there will be a real-time constraint to be met but exceeding it brings
no additional benefit.  In other applications (e.g. microprocessors)
any performance increase is to be seized.
</p>

<h4>How can the speed be improved?</h4>

<p>
How close are you to your target? If you're &lsquo;miles off&rsquo;
you need to restructure your architecture to increase parallelism.
This may be done by:
</p>

<ul>
<li> deeper pipelining &rArr; faster clock

<li> increase logic parallelism &rArr; do more within clock cycle

<li> evaluating several things at once &rArr; do more with slower clock

<li> multi-cycle operations &rArr; sometimes allow more than one period
</ul>

<p>
If close to target you might be able to identify and recode critical
modules.
</p>

<p>
Tools can also be instructed to optimise for certain criteria, such as
speed, power, area, &hellip; Normally gains in one category are paid for in
others.
</p>

<h4>Technology</h4>

<p>
Many cells come in families with various drive strengths.  Increasing the drive
will speed up an output (and slow the input, and probably cost power).
</p>

<p>
It may be possible to use different cell families to improve performance. E.g.
</p>

<ul>
<li> High-speed &mdash; low threshold transistors switch faster but leak more

<li> Standard &mdash; a compromise design

<li> Low-leakage &mdash; high threshold transistors save power but switch slowly
</ul>

<h4>Post-layout &hellip;</h4>

<p>
The process may need repeating.  After the wiring is factored in things
(probably) have slowed down.  Buffers may be added which increase the
latency but speed up edges.
</p>

<p>
Hopefully this process converges on something acceptable.
</p>

<p>
<b>Optimise early</b> to avoid wasting effort on &lsquo;hopeless&rsquo;
designs.  Layout and extraction all take time and more accurate
modelling also takes longer.
</p>

<hr>

<h2>Time Stealing</h2>

<p align="center">(<b>Not</b> something obtained with a simple design flow.)</p>

<center>
<img src="figures/time_stealing.png" alt="Time stealing in a pipeline" width=80%>
</center>

<p>
This is a technique to get a bit more performance out of a pipeline
which is not perfectly balanced.
</p>


<center>
<div class="inset">

<p>
Reminder: a <b>balanced pipeline</b> is one where the the critical
paths of all pipeline stages are (more or less) the same.
</p>

</div>
</center>


<p>
In the first example the critical path is constraining the clock
period; the second stage will evaluate before the result is needed and
the result is delayed by 200&nbsp;ps at the register input.  This is
the &lsquo;normal&rsquo; type of circuit.
</p>

<p>
The second example deliberately introduces some skew into the clock to
one stage.  If clocked at 1&nbsp;GHz this would mean that there was a
100&nbsp;ps wait for this register but, because it was clocked
&lsquo;late&rsquo; the delay to the next register would be smaller
(only 100&nbsp;ps, not 200&nbsp;ps in the example).  The
clock <b>period</b> can now be reduced to 900&nbsp;ps and all the
constraints can still be met; the pipeline goes 11% faster.
</p>

<p>
This is not a trivial process however; there are difficulties:
</p>

<p>
<ul>
<li> Standard design flows will not do this.

<li> There needs to be a well-controlled delay in the clock
distribution tree, which is difficult to make reliable.

<li> There is a stricter hold-time bound on the &lsquo;lengthened&rsquo;
     stage; it must be guaranteed that no logic path will take less
     than 100&nbsp;ps or that data may be captured by the same (but
     delayed) clock edge which initiated it.
</ul>

<h4>Why?</h4>

<p>
<span style="color:blue">Why not &lsquo;simply&rsquo; repartition the logic stages to reduce
the worst critical path?</span><br>
Usually this approach would be a better solution &ndash; and less
stressful when persuading the logic to synthesize at the desired
speed.  However this is not always possible.  Usually this will be due
to the inclusion of some <b>macrocell</b> which cannot sensibly be
subdivided: a typical example of this would be a <b>memory</b> (SRAM)
block which has been synthesized by the ASIC foundry.
</p>

<center>
<div class="inset">

<h3>Two-phase clocks</h3>

<p>
Rather than use master/slave flip-flops can use smaller, transparent
latches.  These are enabled by alternating, <i>non-overlapping</i> clocks.
</p>

<center>
<img src="figures/pipe_2_phase.png" alt="Two-phase pipeline clocking" width=80%>
</center>

&nbsp;<br>

</div>
</center>

<center><font style="color:blue;font-size:30px">** Explain transparent
    latches **</font></center>

<center><font style="color:blue;font-size:30px">** Could animate **</font></center>

<h3>&ldquo;Time borrowing&rdquo;</h3>

<p>
Basically the same principle as time stealing but exploiting
transparent latches rather than edge-triggered flip-flops (see
&ldquo;Two-phase clocks&rdquo;).
</p>

<p>
Because a latch is transparent for some time it allows an
early-arriving result into the next stage before an edge-triggered
device would.  Thus any time spare in one stage will be exploited &ndash;
automatically &ndash; by the next stage.
</p>

<p>
[Don't get too concerned about the <i>names</i> of these techniques;
concentrate on the <i>principle</i>!]
</p>

<p>
<h3><a href="https://ieeexplore.ieee.org/abstract/document/711317">Wave pipelining</a></h3>
</p>

<p>
A &ldquo;wave pipeline&rdquo; is a pipeline <i>without latches</i> to
re-synchronise data elements; inputs change periodically and
&ldquo;waves&rdquo; of evaluation activity chase each other through
the logic.
</p>

<ul>
<li> In principle a wave pipeline could be the fastest means of
implementing logic.

<li> In practice it is very hard<sup>&dagger;</sup> to ensure that all parallel logic operations
take &lsquo;exactly&rsquo; the same time; failure means that part of one data element may catch up with its predecessor, causing a failure.
  <ul>
  <li> As the manufacturing variation of IC devices increases this
gets ever harder.
  </ul>
</ul>
</p>

<p>
Wave pipelining is mentioned here to for completeness rather than as a
suggested technique.
</p>

<blockquote style="font-size:12px;">
<sup>&dagger;</sup>Read as &ldquo;nearly impossible&rdquo;.
</blockquote>

<hr>

<h2>Clock Domains <span style="color:red;font-size:24px">&star;</span></h2>

<img src="figures/clock_domains.png" alt="Clock domains on a chip" width= 30% align="right">

<p>
Synchronous design is a Good Thing
</p>

<ul>
<li> Simplifies RTL design
  <ul>
  <li> May be easier to think about state diagrams
  </ul>

<li> Simplifies debugging &ndash; can take a &lsquo;global&rsquo; view
  of <b>state</b>

<li> Tool chains optimised for such
</ul>

<p>
However it is not always possible to have one clock across an SoC.
</p>

<ul>
<li> Synchronous clock distribution increasingly difficult.

<li> Blocks may work optimally at different frequencies:
  <ul>
  <li> May be IP from different vendors
  </ul>

<li> Some I/O may require specific frequencies.
</ul>
<br clear="right">
<hr>

<h2>Frequency and phase</h2>
</p>

<p>
It's only meaningful to talk about <i>frequency</i> with respect to
repetitive signals.
</p>

<p>
The <b>frequency</b> of a clock is the reciprocal of its <b>period</b>.
&nbsp; &nbsp;
f&nbsp;=&nbsp;1&frasl;T
</p>

<center>
<img src="figures/frequency_1.png" alt="Frequency definition" width=50%>
</center>

<p>
With two or more signals there may be a phase relationship.
</p>

<p>
Same frequency, different phase.
</p>

<center>
<img src="figures/frequency_2.png" alt="Frequency & phase" width=50%>
</center>

<p>
Harmonic frequencies (phase relationship is fixed)
</p>

<center>
<img src="figures/frequency_3.png" alt="Frequency harmonics" width=50%>
</center>

<p>
Non-harmonic frequencies: phase relationship drifts
</p>

<center>
<img src="figures/frequency_4.png" alt="Frequency non-harmonics" width=50%>
</center>

<p>
It is increasingly common to have <b>blocks</b> running at different
frequencies.  This is sometimes referred to as <b>GALS</b>
<b>G</b>lobally <b>A</b>synchronous <b>L</b>ocally <b>S</b>ynchronous.
</p>

<p>
Or possibly the same frequency, but &lsquo;uncertain&rsquo; phase.
</p>

<p>
<ul>
<li> Sometimes just reduce (divide) master clock

<li> Sometimes have separate clocks.
</ul>

<h2>Oscillators</h2>

<h4>Crystal oscillators</h4>

<p>
The normal clock source for digital logic is a crystal-controlled
oscillator.  These use vibrations in a carefully machined (piezo
electric, usually quartz) crystal to stabilise an electrical
oscillator circuit.  Without any special care a frequency within about
50ppm<sup>&dagger;</sup> is usual.  If it matters, much greater
stability is, of course, achievable as is demonstrated by
&lsquo;quartz clocks&rsquo;.
</p>

<ul>
<li> No two <i>independent</i> oscillators will run at exactly the
  same frequency.

<li> If a constant phase relationship is required a single oscillator must
be used.
</ul>

<blockquote style="font-size:12px;">
<sup>&dagger;</sup>Equivalent to about 4&nbsp;s error per day.
</blockquote>

<h4>Frequency examples</h4>

<ul>
<li> Digital logic is operated at frequencies of several GHz
  <ul>
  <li> For ASIC design, <i>typically</i> think 100s MHz
  </ul>

<li> Humans tend to prefer simple numbers such as 20&nbsp;MHz

<li> A &lsquo;serial line&rsquo; (old fashioned now) has standard baud
  rates of 9600, 19200, 38400, 115200 &hellip; Hence multiples of such
  frequencies are not uncommon.
  <ul>
  <li> Example: 18.432&nbsp;MHz&nbsp;=&nbsp;30&nbsp;&times;&nbsp;16&nbsp;&times;&nbsp;38400&nbsp;=10&nbsp;&times;&nbsp;16&nbsp;&times;&nbsp;115200
  </ul>

<li> USB uses bit rates of 12&nbsp;Mb/s (USB 1),&nbsp;480 Mb/s (USB&nbsp;2)

<li> In I/O applications there is commonly some tolerance.
  <ul>
  <li> E.g. RS232 &plusmn; a few percent
  <li> USB&nbsp;480.00&nbsp;Mbit/s &plusmn;500&nbsp;ppm,
  12.000&nbsp;Mbit/s&nbsp;&plusmn;2500 ppm
  </ul>
</ul>

<h4>Clocking and power</h4>
</p>

<p>
The clock network is a significant source of power dissipation.  The
power used is (effectively) proportional to clock frequency.  Thus it
makes no sense to clock a circuit faster than is necessary.  <b>Clock
gating</b> may be introduced to stop clocks when a block is unused
&ndash; but this should be done with caution!
</p>

<hr>

<h2>Crossing clock domains</h2>

<p>
There are various possibilities for relationships between clocks.
</p>

<p>
<ul>
<li> Synchronous circuits avoid this difficulty

<li> <b>Isochronous</b> circuits have a known, constant, phase relationship
  <ul>
  <li> Maybe with blocks with <b>harmonic</b> frequencies
  <li> This may be exploited (with care!) in inter-block communication
  </ul>

<li> Asynchronous clock sources cause problems!
  <ul>
  <li> Sending signals between asynchronous domains
       is <b><u>impossible</u> with 100% reliability</b>.
  <li> At some stage a flip-flop set-up/hold constraint <b>will</b> be
       violated.
  <li> We can make the probability of failure <b>very small</b>.
  </ul>
</ul>
</p>

<p>
There is also the need for <b>arbitration</b>: <i>which</i> receiver
cycle did the data arrive in?
</p>

<p>
<hr>

<h2>Metastability</h2>
</p>

<p>
A model flip-flop
</p>

<center>
<img src="figures/metastability.png" alt="Metastability" width=70%>
</center>

<ul>
<li> The flip-flop has <i>three</i> stable positions: &lsquo;0&rsquo;,
  &lsquo;1&rsquo; and a <b>metastable</b> position
  &lsquo;half-way&rsquo; between.

<li> Violating set-up/hold conditions can result in the flip-flip entering
the metastable state.

<li> In principle the flip-flop can stay metastable indefinitely
  <ul>
  <li> But if it starts to resolve one way, positive feedback pushes
    it further in that direction
  </ul>

<li> The probability of <i>remaining</i> metastable decreases
  exponentially with time.
</ul>

<p>
The dangers in a metastable state lie in that it can be interpreted as
different values by different inputs, or at different times.  A
possible metastable flip-flop should only go to one place.
</p>


<center>
<div class="inset">

<h3>Synchroniser flip-flops</h3>

<div class="row"> 
 <div class="column">

  <p>
  Some cell libraries provide flip-flops specifically to address this
  problem.  They can still go metastable but they have a
  &lsquo;steeper hill&rsquo; so they tend to resolve more quickly.
  This is done by strengthening the gain internally, which makes them
  slower (longer propagation delay) and probably raises power
  consumption.  Use them in the synchroniser role, if available,
  otherwise stick to the &lsquo;standard&rsquo; flip-flop.
  </p><br clear="right">
  </div>

 <div class="column">
  <img src="figures/sync_ff.png" alt="'Normal' and synchroniser
				    flip-flops" width= 90% align="right">
  </div>
</div>

</div>
</center>

<hr>

<h2>Synchronisers</h2>

<img src="figures/synchroniser.png" alt="Synchroniser" width= 40% align="right">

<p>
A typical synchroniser looks like this:
</p>

<p>
Operation is simple.
</p>

<p>
If the first flip-flop latches a valid level the second one copies
this one clock period later.
</p>

<p>
Else the first flip-flop may go metastable but has a whole clock
period to resolve to a digital state.  As the violation is caused by an
input data transition the chosen state will determine whether the data
changed before or after the clock.
</p>

<p>
If determined that the data changed &lsquo;after&rsquo; the clock then
it will be picked up on the next clock edge.
</p>

<p>&nbsp;</p>

<p>
The first flip-flop <i>probably</i> doesn't remain metastable for a
whole clock period.  The probability depends on the properties of the
flip-flop and the length of the clock period.
</p>

<p>
If the flip-flop doesn't resolve in time it will be forced to a
digital state on the next clock edge &ndash; but the second flip-flop may go
metastable.
</p>

<p>
Paranoid designers may add more flip-flops.  Each multiplies the
probability of remaining metastable by the same small number, thus if
(say) 1 in 10<sup>6</sup> is too high, go for 1 in 10<sup>12</sup> , 1
in 10<sup>18</sup> , etc.  Each flip-flop (delay) also increases the
latency, of course.
</p>

<p>
There is <b>no certain guarantee</b> that this will always work.
However the probability of failure can be made <i>very</i> small.
</p>

<p>
[Remember that 3&nbsp;GHz translates to 3&times;10<sup>9</sup>
clocks/second or about 10<sup>19</sup>/century.]
</p>

<hr><hr>

<p>
<h1>Crossing clock domains</h1>
</p>

<p>
There is no need to synchronise <i>every</i> signal crossing a
boundary explicitly.
</p>

<center>
<img src="figures/clock_domain_data.png" alt="Data bus crossing to new
					      clock domain">
</center>

<p>
If the request is synchronised, accompanying data will have had plenty
of time to arrive.
</p>

<p>
When crossing a clock boundary, there is always:
</p>

<p>
<ul>
<li> some <b>latency</b>

<li> a <b>chance of failure</b> due to persistent metastability
  <ul>
<li> small: may be reduced by adding extra flip-flops
<li> special flip-flops which resolve faster may be available<br>
(though not from logic synthesis!)
  </ul>
</ul>
<hr>

<h2>Crossing timing domains in the lab.</h2>
</p>

<p>
The system we are constructing has been kept as synchronous as
possible.  Thus the master frequency is set by the pixel clock and the
drawing engine is run at the same rate.  There is, however, an
asynchronous input in terms of the processor bus, which is governed by
a completely separate clock.
</p>

<img src="figures/memory_timing_async.png" alt="Asynchronous memory
			write timing" width= 40% align="right">

<p>
The bus arriving from the ARM is an &lsquo;asynchronous&rsquo; bus.  In this
context this means there is no clock signal within the bus.  Timing is
provided by pulses on control signals, the length of which is governed
by the bus master (i.e. the processor).  This type of bus is a typical
&ndash; arguably &lsquo;old fashioned&rsquo; &ndash; interface used by many memory and I/O
devices.  The various parameter registers are therefore built as
transparent latches, enabled by the strobe pulses.
</p>

<p>
Most of the time, writing to the interface has no effect on the
clocked part of the circuit.  Parameters are set up but not yet
read.  This happens on &lsquo;software&rsquo; timescales where it is easy to be
confident the values will be stable long before they are
used.  Synchronization is therefore unnecessary.
</p>

<p>
When a command is issued a signal must cross into the clocked
domain.  In this case the synchroniser shown here is used.
</p>

<p style="font-family: 'Courier New', monospace;">
&nbsp; always @ (posedge uP_nwr, posedge cmd_ack)<br>
&nbsp; if (cmd_ack) go <= 0;<br>
&nbsp; else<br>
&nbsp; &nbsp; if (!uP_ncs && (uP_address == 6`h08)) go <= 1;<br>
&nbsp;<br>
&nbsp; always @ (posedge clk, posedge cmd_ack)<br>
&nbsp; &nbsp; if (cmd_ack) begin go_1 <= 0; &nbsp;cmd_req <= 0; &nbsp; &nbsp;end<br>
&nbsp; &nbsp; else &nbsp; &nbsp; &nbsp; &nbsp; begin go_1 <= go; cmd_req <= go_1; end<br>
</p>

<img src="figures/clock_sync.png" alt="Lab. clock synchroniser" width= 40% align="left">

<p>
The operation is triggered by the end of the write pulse which allows
time for data to be propagated through transparent latches in the same
cycle.  cmd_ack is a one clock long pulse in response to an accepted
cmp_req from the synchronous side.
</p>

<p>
There is an assumption that a second write will not occur &lsquo;too
soon&rsquo;.  This can be prevented by, for example, checking the
&lsquo;go&rsquo; signal in software as a status bit.
</p>

<p>
A status bit could be cleared at an arbitrary time unless it is
resynchronised for the processor.  This is difficult without access to
the processor's clock.  However if read into a processor register the
bit is likely to pass through several flip-flops and thus have settled
into some digital state by the time it is read and tested.  If sampled
in a polling loop it can be deduced that, if a bit is read just as it
changes, it doesn't matter how it's interpreted.
</p>

<p>
The other possible output for such a bit is as an interrupt
signal.  Interrupts are routinely regarded as asynchronous and fed
through synchronisers on entry to a processor.  Any additional latency
is small compared with the software run time.
</p><br clear="left">

<center>
<div class="inset">
<h3>Asynchronous arbitration</h3>

<p>
It <i>is</i> possible to enter an asynchronous domain with 100%
reliability using an arbiter or <i>mutual exclusion</i> element.  This
is a cell which determines which of its (usually two) inputs arrived
&lsquo;first&rsquo;.  It achieves reliability by <i>detecting</i>
metastability and <i>delaying its decision</i> until this is resolved.
</p>

<p>
Unfortunately the time taken to make a decision is unbounded so this
process could always take more than a clock period &ndash; however
long that is.
</p>
</div>
</center>

<h1>Crossing clock domains</h1>

<p>
Synchronisers introduce latency and may &lsquo;cripple&rsquo;
performance:
</p>

<center><font style="color:red;font-size:30px">** FIGURE **</font></center>

Synchronising every item: low bandwidth

<center><font style="color:red;font-size:30px">** FIGURE **</font></center>

Buffer &lsquo;packet&rsquo;: longer latency, higher bandwidth

<center><font style="color:red;font-size:30px">** FIGURE **</font></center>

FIFO
Read/write FIFO: low(ish) latency,
high bandwidth &ndash; more complex

<center><font style="color:red;font-size:30px">** FIGURE **</font></center>

<p>
More buffers reduce waiting time
</p>

<p>
Various solutions are possible, depending on requirements & complexity.
</p>

<center><font style="color:blue;font-size:30px">** Ideal for some animation **</font></center>

<hr>

<img src="figures/clock_domain_crossing.png" alt="Clock domain
  crossing" width= 50% align="right">

<img src="figures/clock_domain_timing.png" alt="Clock domain
  crossing timing diagram" width= 53% align="right">

<p>&nbsp;</p>

<h2>Crossing clock domains</h2>

<p>&nbsp;</p>
<p>
Synchronisation introduces latency.  The probability of error decreases
(exponentially) with the time allowed to resolve any
metastability.  This also slows down the communications.
</p>

<p>&nbsp;</p>

<p>
The details may vary and there may be the possibility to optimise a
bit but the point to note is that the complete <i>handshake</i> needs
to synchronise <i>twice</i> &ndash; once on its way into each clock
domain &ndash; so the overall cycle time is slow.  The exact latency
may vary depending on the clock's frequencies and phase difference.
</p>

<font style="color:blue;">** This could animate, too. **</font>

<br clear="right">

<h4>Optimisation?</h4>

<p>
Removing the flip-flops delaying
<span style="font-family: 'Courier New', monospace;">a&rArr;b</span>
and
<span style="font-family: 'Courier New', monospace;">w&rArr;x</span>
would reduce the cycle
time. &nbsp; <span style="color:red"><b>** DANGER **</b></span> &nbsp;
If, as is likely, w (for example) is generated from combinatorial
logic it could glitch to the wrong value during evaluation.  If such a
glitch is captured by the other clock, all sorts of problems may
occur! The flip-flops filter out any glitches.
</p>

<center>
<div class="inset">
<h3>Two modules at the &lsquo;same&rsquo; frequency &ndash; with
  independent clocks</h3>

<p>
Sometimes it is expedient to have communications between units with
notionally the &lsquo;same&rsquo; clock frequency although they have
different clock sources.  Examples may include synchronous serial
communication such as
<a href="https://en.wikipedia.org/wiki/PCI_Express">PCIe</a>
or <a href="https://en.wikipedia.org/wiki/S-ATA">S-ATA</a>.
However, <i>no two clocks will </i>exactly<i> match</i> so one end of
the link will be faster than the other.
</p>

<p>
A mechanism to allow for this disparity is for the transmitter to
insert &lsquo;comma&rsquo; symbols into the communications stream.
These carry no data, hence imposing a small overhead.  The receiver
maintains a FIFO of incoming symbols which it is synchronising to its
own clock.  If its clock is a little slower the FIFO will gradually
fill; if its clock is a little faster the FIFO will gradually
empty.  When a comma symbol is seen, if the FIFO is getting close to
full the comma is discarded, saving some time and catching up;
conversely, if the FIFO is close to empty the comma allows the
receiver a slight pause.  In this way the FIFO can be kept close to
half-full at all times and the communication maintained seamlessly.
</p>
</div>
</center>

<p>
<h2>Buffering</h2>
</p>

<p>
A circuit can pass one &lsquo;thing&rsquo; per clock cycle to another
circuit in the same clock domain.
</p>

<p>
Synchronising latency will apply to every &lsquo;thing&rsquo; passed
across an interface between clock domains.  This reduces the
communication bandwidth considerably (in things/cycle).
</p>

<p>
Here are a couple of (related) techniques to achieve higher bandwidth
across the interface.
</p>

<p>
<b>Pack many bytes into a &lsquo;thing&rsquo;.</b>  Fill up a
&lsquo;bucket&rsquo; (RAM) of data then signal its transfer at the
end.  There is one synchronisation penalty for the bucketload which is
shared by all the data.  The disadvantage of this is that the latency
is increased because the bucket must be filled then the transfer
requested, so the first datum takes longer to be received (although
they come close together after that.
</p>

<p>
As above but <b>double buffer</b>.  Fill up a bucket and notify the receiver
that it's ready.  Whilst that is synchronising and being emptied, fill
up the next one.  The disadvantage is that more (independent) RAMs are
needed; the advantage is increased bandwidth, closer to the maximum
rate (which is the slower of the corresponding processes).
</p>

<p>
A <b>decoupling FIFO</b> can extend the concept further.  Conceptually
this is a bit harder to conceive.  Think of a dual-port RAM (you could
build it out of flip-flops) where the transmitter writes to successive
locations and the receiver subsequently reads them at its own rate.
Every time a write completes a &lsquo;counter&rsquo; is incremented
(Tx clock) and when a read completes it is decremented (Rx clock).
The control logic does need a synchroniser but synchronisation is not
necessary every cycle: for example if the FIFO contains four data,
following a read it contains at least three (more if writes are
ongoing) so no need to check before reading the next one.  This can be
complicated to build but can offer close to maximum throughput with
close to minimum latency.
</p>

<hr><hr>

<h2>Changing frequency</h2>

<img src="figures/clock_division.png" alt="Clock division
	   multiplication" width= 50% align="right">

Reducing frequency &ndash; by an integer factor &ndash; is easy.

<ul>
<li> Note that dividing by an odd number will result
in an uneven duty-cycle
  <ul>
  <li> This may or may not matter to you
  </ul>

<li> The output clock will have a fixed (unknown) phase relationship
  with the input.<br clear="right">
</ul>

<p>
Increasing frequency is more difficult: use a Phase-Locked Loop (PLL)
</p>

<center>
<img src="figures/clock_multiplication.png" alt="Clock multiplication"
     width=80%>
</center>

<p align="center">
These include some mixed-signal (analogue) components &hellip;<br>
&hellip; but can usually be bought-in from a specialist designer.
</p>


<h3>Why bother?</h3>

<ul>
<li> It is difficult to carry UHF signals across a PCB; great care with
tracking is required.

<li> Switching signals dissipates power.  The more you switch, the more
it costs.

<li> Switching signals transmits Radio Frequency Interference (RFI).
(Where do you think the power goes?)
This is a Bad Thing, and may be illegal.

<li> Generating stable clocks at UHF directly is impractical.
</ul>

<p>
A typical clock source will be a crystal controlled oscillator.  These
are cheap and quite precise.  Frequencies of the order 1-100&nbsp;MHz
50ppm are readily available.  However modern computers are typically
clocked much faster.
</p>

<p>
So, the usual ploy is to supply a stable frequency (say 20&nbsp;MHz)
to the chip and then multiply this on board to the desired clock rate.
</p>

<p>
A bonus from this strategy is that the clock multiplier is digital and
can be controlled (e.g. in software) allowing a trade-off between
performance and power consumption.
</p>

<p>
Another strategy is to reduce the clock rate &ndash; to reduce power
dissipation &ndash; if the chip is becoming too hot.
</p>

<center>
<div class="inset">

<h3>Clock Gating</h3>

<p>
If part of a device is not in use, its clock may be stopped
(&lsquo;gated&rsquo;).  This is more power-economic than simply
&lsquo;disabling&rsquo; the registers because it prevents (parts of)
the clock tree from switching.
</p>

<p>
However there are several concomitant hazards and it's easy to introduce
unpleasant clock skew or even glitches if care is not exercised.  Don't do
this &lsquo;by hand&rsquo; until you've lots of experience!
</p>

<p>
This is an option <b>best left to the tools</b> (if available).  Note
that adding gating may compromise peak performance so is not always
desirable.
</p>

</div>
</center>

<hr>

<h2>Phase-Locked Loops (PLLs)</h2>

<p>
A PLL is a machine capable of matching the frequency of an input
signal.
</p>

<h4>Everyday example</h4>

<p>
Consider a television set.  It must display images at the same rate as
they are broadcast.  Thus it needs <u>synchronisation</u> information so that
it can adjust its internal timing to match the transmitter.  Of
course, in modern sets at these slow speeds this can be done digitally
by varying the number of &lsquo;local&rsquo; clock cycles in each
line, frame, etc. slightly.<br>
You can see this in the lab. (phase&nbsp;3) with the
&lsquo;sync.&rsquo; signals running to(wards) the monitor.


<h4>Clock multiplication</h4>

<p>
The figure above shows a clock multiplier which works by matching a
division of an output clock to an input reference.
</p>

<center>
<img src="figures/eq_1.png" alt="Frequency multiplication" width=30%>
</center>

<h4>LPF &ndash; Low Pass Filter</h4>

<p>
A typical phase comparator produces pulses on its outputs which
indicate which input edge came first.  These need <b>integrating</b>
(smoothing) to produce a voltage which is (approximately) stable over
many clock periods.
</p>

<h4>VCO &ndash; Voltage Controlled Oscillator</h4>

<p>
An oscillator which runs &lsquo;naturally&rsquo; in a certain range of
frequencies which is &lsquo;tuned&rsquo; by an analogue input voltage.
</p>

<p>
Because a PLL circuit is controlled by feedback its output frequency
will vary slightly around the nominal frequency.  This contributes
to <b>clock jitter</b> &ndash; the perceived variation in clock
frequency.  Jitter is a Bad Thing because the logic must always
evaluate within the <i>shortest</i> clock period (<i>not</i> the
average) and the more variation there is the shorter this minimum time
will be.
</p>

<center>
<div class="inset">

<h3>Definitions to remember</h3>

<ul style="text-align:left">
<li> Skew: the difference in arrival time of a signal at different destinations.

<li> Clock jitter: the variation of a clock frequency around its
  specified value.
</ul>

</div>
</center>

<hr><hr>

<h1>Miscellany</h1>

<p>
A collection of other timing-related issues.
</p>

<h2>Timing checking tools</h2>

<p>
A number of tools exist to assist with timing closure.  Many of these
are only appropriate when a physical realisation of the chip is
available.
</p>

<ul>
<li> Static Timing Analysis (STA)

<li> Edge speed analysis

<li> Hold time checking

<li> Clock skew analysis

<li> &hellip;
</ul>

<h2>Multi-cycle paths</h2>

It is sometimes expedient (and convenient) to allow logic more than
one clock period to settle.

This may be sensible but you need to tell the tools.

<hr>

<h2>Tools</h2>

<p>
A <a href="https://en.wikipedia.org/wiki/Static_timing_analysis"><b>Static
Timing Analyser</b></a> (introduced earlier) will give an
estimate of the critical path in a system by searching all paths
between clocked registers and finding the slowest.  This then sets the
&lsquo;standard&rsquo; for other logic speeds; there is (usually) no
point in optimising any logic paths already faster than the critical
path.
</p>

<p>
The delay of the <b>critical path</b> will depend on the number of serial
logic gates, their type, the fanout and other factors affecting the
electrical load (particularly wire lengths) and their output impedance
or &lsquo;drive strength&rsquo;.  All these factors go into &lsquo;the
mix&rsquo; when attempting to optimise the circuit.
</p>

<p>
Typically, <b>synthesis tools</b> will have <b>options</b> which allow
the engineer to put more importance on speed, size, power etc.  It may
be that a circuit can be optimised for speed but this may result in it
being larger or more power hungry.
</p>

<p>
<b>Edge speeds</b> are the time it takes a digital circuit to switch
between states.  They depend on the outputting gates drive and the
(capacitive) load it needs to switch.  Edges which are &lsquo;too
slow&rsquo; may introduce problems such as:
</p>

<ul>
<li> induced noise near the threshold may be received and amplified

<li> different target gates may &lsquo;see&rsquo; the input switch at
  (significantly) different times

<li> increased time spent near the &lsquo;half way&rsquo; level may
  result in an extra power drain
</ul>

<p>
Tools are available to identify any slow<sup>&dagger;</sup> edges,
possibly for further attention.
</p>

<blockquote style="font-size:12px;">
<sup>&dagger;</sup>The user can define what &ldquo;slow&rdquo; means.
</blockquote>

<p>
With &lsquo;challenging&rsquo; speed targets a flip-flop may be
designed with a data hold time longer than its propagation delay.  With
such it would be dangerous to connect one flip-flop output directly to
another's input.  Any logic in-between will naturally act as an
additional delay and help meet the true constraints.  <b>Hold-time
checking</b> will identify any remaining risks here and allow extra
buffer insertion.
</p>

<p>
Note that problems with a too-long critical path may be accommodated
by reducing the clock frequency.  Hold-time problems are a property of
the circuit and there is no cure if they appear in the chip!
</p>

<center>
<div class="inset">

<h3>Frequency and power</h3>

The majority of the power dissipation in CMOS logic is dynamic; it
occurs when gates/wires switch.  Thus &ndash; when executing &ndash;
the power dissipation is roughly proportional to the clock
frequency.  Reducing the frequency saves power (dissipates less heat).<br>

&nbsp;<br>
</div>
</center>

<h3>Delay lines</h3>

<p>
It <i>is</i> possible &ndash; and sometimes necessary &ndash; to build
delays onto ASICs.  An approximate delay can be produced with a
&lsquo;chain&rsquo; of inverters or buffers; the actual delay on a
given design and process may vary by a factor of two or more depending
on the manufacturing and operation conditions of the chip.
</p>

<p>
Precise delays need to be calibrated against a reliable reference
frequency.  These are typically chains of gates (as above) whose
length can be altered (e.g.  by multiplexing output taps) to give the
nearest available approximation to the required delay.  Periodic
recalibration may be needed due to thermal drift.
</p>

<p>
An example would be a
<a href="https://en.wikipedia.org/wiki/Delay-locked_loop"><b>Delay-Locked Loop</b></a>
(DLL).  For instance Xilinx FPGAs contain a small number of DLLs which
allow the insertion of a known delay.  A typical application is to
delay a clock signal so that edges at the leaves of the distribution
tree are in phase (via a <i>total</i> delay of a number of clock
cycles) with an incoming reference.  This effectively
&lsquo;removes&rsquo; the clock buffer delays.
</p>

<center>
<div class="inset">

<h3>Chip variation</h3>

<p>
Gate speed depends on various manufacturing and operation conditions,
normally referred to as &lsquo;PVT&rsquo; for Process, Voltage, Temperature.
</p>

<ul style="text-align:left">
<li> Process: variation in manufacturing such as transistor doping density.

<li> Voltage: the supply voltage at a gate will be less than that at
the chip's pins (Ohm's Law); this varies across the chip and may
fluctuate due to other power demands elsewhere.

<li> Temperature: hotter is slower.
</ul>

</div>
</center>

<hr><hr>

</body>
